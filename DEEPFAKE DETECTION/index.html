<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Recognition</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            margin: 50px;
        }
        button, input {
            padding: 10px 15px;
            font-size: 16px;
            margin: 10px;
            cursor: pointer;
        }
        #transcription {
            margin-top: 20px;
            font-size: 18px;
            color: #333;
        }    </style>
        </head><body>
    <div style="padding: 20px; margin: 20px; background-color: rgb(81, 173, 173); height: 600px;">
            <h2 style="font-weight: bold;margin: 30px;">AI Voice Recognition with Deepgram</h2>   
            <button id="startRecord" class="btn btn-success">üé§ Start Recording</button>
            <button id="stopRecord" disabled class="btn btn-danger">‚èπ Stop Recording</button><br><br>    
            <input type="file" id="audioUpload" accept="audio/*">
            <button id="uploadFile" class="btn btn-primary">üì§ Upload & Transcribe</button>
        <div style="background-color: white; margin: 50px;padding: 20px; margin-top: 100px;">
            <p id="transcription" >Transcription will appear here...</p>
        </div>
    </div>
    <script>
        let mediaRecorder;
        let audioChunks = [];
        document.getElementById("startRecord").addEventListener("click", async () => {
            audioChunks = [];
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.ondataavailable = event => audioChunks.push(event.data);
            mediaRecorder.onstop = () => sendAudioToDeepgram(new Blob(audioChunks, { type: "audio/wav" }));
            mediaRecorder.start();
            document.getElementById("startRecord").disabled = true;
            document.getElementById("stopRecord").disabled = false;
        });
        document.getElementById("stopRecord").addEventListener("click", () => {
            mediaRecorder.stop();
            document.getElementById("startRecord").disabled = false;
            document.getElementById("stopRecord").disabled = true;
        });
        document.getElementById("uploadFile").addEventListener("click", () => {
            const fileInput = document.getElementById("audioUpload");
            if (fileInput.files.length === 0) {
                alert("Please select a file first.");
                return;
            }
            sendAudioToDeepgram(fileInput.files[0]);
        });
        async function sendAudioToDeepgram(audioBlob) {
            const response = await fetch("https://api.deepgram.com/v1/listen", {
                method: "POST",
                headers: {
                    "Authorization": "Token 6bc62f18b8e57f692921d0cf37c651ba9bb1e981"
                },
                body: audioBlob
            });
            const data = await response.json();
            document.getElementById("transcription").innerText = data.results.channels[0].alternatives[0].transcript || "No speech detected.";
        }
    </script>
</body>
</html>
